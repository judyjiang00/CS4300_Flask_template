{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import io\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "regions = ['africa',\n",
    "           'antarctica',\n",
    "           'australasia',\n",
    "           'caribbean',\n",
    "           'central_america',\n",
    "           'central_asia',\n",
    "           'europe',\n",
    "           'indian_subcontinent',\n",
    "           'middle_east',\n",
    "           'north_america',\n",
    "           'north_east asia',\n",
    "           'pacific',\n",
    "           'south_america',\n",
    "           'south_east_asia',\n",
    "           'north_east_asia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NoahKaplan/miniconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse FlatCorpus into 2D arrays\n",
    "data = []\n",
    "with io.open('data/FlatCorpus.txt', encoding='utf-8-sig') as f:\n",
    "    for line in f:\n",
    "        title, text = line.split(':  ')\n",
    "        region = ''\n",
    "        for r in regions:\n",
    "            if title.startswith(r):\n",
    "                # Replace with space and capitalize\n",
    "                region = ' '.join(map(lambda x: x.capitalize(), r.split('_')))\n",
    "                break\n",
    "        split_title = title[len(region) + 1:].split('_')\n",
    "        # Last item of underscore-split title is the entry type, remove file extensions\n",
    "        entry_type = split_title[-1].split('.')[0]\n",
    "        # Everything else is city name, capitalize\n",
    "        city = ' '.join(map(lambda x: x.capitalize(), split_title[:-1]))\n",
    "        \n",
    "        # Filter out non-descriptive words\n",
    "        row = [region, city, entry_type, text]\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "['North America', u'Atlantic City', u'activities', u\"Activities  Atlantic City is not the place to visit if you're into the outdoors. The most burning of calories you'll achive will be getting out of bed and slouching in front of a slot machine. The city's rules and regulations conspire to keep it this way. While the Boardwalk is a good spot, in theory, for cycling, bikes are only allowed between the hours of 6-10 am.  If you want some exercise, you're better off leaving Atlantic City and heading for the peaceful Pine Barrens, where there's no shortage of hiking in the huge pine forest. In Egg Harbor, you can rent equipment to canoe and kayak through the Pines. Wildwood's coast has some decent beaches from which people parasail. Whalewatching trips run from North Wildwood and Cape May throughout the summer.  \\n\"]\n"
=======
      "['North America', 'Aspen', 'obt', \"Off the Beaten Track  About 70mi (113km) long from its start near Independence Pass to the Colorado River, the Roaring Fork is a body of water with one free-flowing personality. The Ute Indians, early residents of the area, named it 'Thunder River,' and it isn't a stretch to imagine why. In its relatively short distance it changes drastically in elevation - shifting about 7000ft (2134m) total - making for variable, erratic depths and scenery that takes in everything from dramatic canyons to aspen-treed landscapes. It's the rushing artery of Aspen with all manner of activities surrounding it. Scenic whitewater trips are available with local guides; full daytrips generally include lunch. Fishers reel in trout (brown and rainbow) and whitefish - the river is said to have the best winter fishing in the state.  \\n\"]\n"
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
     ]
    }
   ],
   "source": [
    "print(data[1160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1801\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 5,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [row[0] for row in data]\n",
    "cities = [row[1] for row in data]\n",
    "types = [row[2] for row in data]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 6,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/NoahKaplan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 7,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return re.findall('[a-zA-Z]+', sent)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 8,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [[w.lower() for w in tokenize(row[3])] for row in data]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 9,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'attractions', u'officially', u'the', u'capital', u'the', u'government', u'long', u'ago', u'moved', u'itself', u'and', u'most', u'of', u'its', u'business', u'km', u'mi', u'west', u'to', u'cotonou', u'nevertheless', u'this', u'town', u'of', u'some', u'people', u'remains', u'a', u'beautiful', u'and', u'historical', u'place', u'its', u'proximity', u'to', u'the', u'nigerian', u'border', u'gives', u'the', u'appearance', u'that', u'more', u'is', u'going', u'on', u'than', u'actually', u'is', u'though', u'there', u'are', u'still', u'some', u'hot', u'spots', u'such', u'as', u'the', u'grand', u'marche', u'd', u'adjara', u'where', u'you', u'can', u'buy', u'drums', u'cloth', u'baskets', u'and', u'the', u'best', u'pottery', u'in', u'benin', u'the', u'musee', u'ethnographique', u'de', u'porto', u'novo', u'has', u'a', u'great', u'collection', u'of', u'yoruba', u'artefacts', u'you', u'can', u'also', u'visit', u'the', u'ornate', u'brazilian', u'style', u'church', u'now', u'a', u'mosque']\n"
     ]
    }
   ],
   "source": [
    "print(descriptions[1])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 10,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 11,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = [[stemmer.stem(w.lower()) for w in sent] for sent in descriptions]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 12,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'attract', u'offici', u'the', u'capit', u'the', u'govern', u'long', u'ago', u'move', u'itself', u'and', u'most', u'of', u'it', u'busi', u'km', u'mi', u'west', u'to', u'coton', u'nevertheless', u'thi', u'town', u'of', u'some', u'peopl', u'remain', u'a', u'beauti', u'and', u'histor', u'place', u'it', u'proxim', u'to', u'the', u'nigerian', u'border', u'give', u'the', u'appear', u'that', u'more', u'is', u'go', u'on', u'than', u'actual', u'is', u'though', u'there', u'are', u'still', u'some', u'hot', u'spot', u'such', u'as', u'the', u'grand', u'march', u'd', u'adjara', u'where', u'you', u'can', u'buy', u'drum', u'cloth', u'basket', u'and', u'the', u'best', u'potteri', u'in', u'benin', u'the', u'muse', u'ethnographiqu', u'de', u'porto', u'novo', u'ha', u'a', u'great', u'collect', u'of', u'yoruba', u'artefact', u'you', u'can', u'also', u'visit', u'the', u'ornat', u'brazilian', u'style', u'church', u'now', u'a', u'mosqu']\n"
     ]
    }
   ],
   "source": [
    "print(stems[1])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 13,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_idx = defaultdict(set)\n",
    "for i, row in enumerate(stems):\n",
    "    for w in row:\n",
    "        inv_idx[w].add(i)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{771, 516, 773, 774, 775, 648, 776, 650, 778, 901, 782, 912, 785, 658, 661, 789, 917, 920, 25, 667, 668, 925, 1311, 928, 417, 676, 804, 805, 807, 934, 936, 688, 818, 437, 949, 696, 952, 1081, 956, 573, 1411, 447, 582, 199, 967, 841, 716, 78, 720, 722, 985, 90, 1116, 605, 607, 1503, 867, 362, 748, 621, 880, 115, 885, 890, 379, 892, 766, 763}\n"
     ]
    }
   ],
   "source": [
    "print(inv_idx['castl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 10\n",
    "max_df = 0.8\n",
    "nd = len(data)\n",
    "vocab = list(filter(lambda x: min_df <= len(inv_idx[x]) <= nd * max_df and x not in stopwords, inv_idx.keys()))\n",
    "vocab_idx = {w: i for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3068\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {}\n",
    "filt_inv_idx = {}\n",
    "for w in vocab:\n",
    "    idf[w] = np.log((nd) / (1 + len(inv_idx[w])) + 1)\n",
    "    filt_inv_idx[w] = inv_idx[w]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 18,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_mat = np.zeros((nd, len(vocab)))\n",
    "\n",
    "for i, row in enumerate(stems):\n",
    "    counter = Counter(row)\n",
    "    for w, count in counter.items():\n",
    "        if w in idf:\n",
    "            doc_mat[i, vocab_idx[w]] = idf[w] * count\n",
    "norm = np.linalg.norm(doc_mat, axis=1)[:, np.newaxis] + 1e-8\n",
    "doc_mat = doc_mat / norm"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['warm', u'tropic', 'beach']\n"
     ]
    }
   ],
   "source": [
    "raw_query = tokenize('warm tropical beach')\n",
    "query = [stemmer.stem(w) for w in raw_query]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum = np.zeros(len(data))\n",
    "for q in query:\n",
    "    if q in vocab_idx:\n",
    "        for doc in inv_idx[q]:\n",
    "            accum[doc] += doc_mat[doc, vocab_idx[q]]\n",
    "ranking = accum.argsort()[::-1]\n",
    "regions = []\n",
    "\n",
    "for r in ranking:\n",
    "    if len(regions) >= 20:\n",
    "        break\n",
    "    regions.append(data[r][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
=======
   "execution_count": 19,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'South Korea', u'Aruba', u'Los Angeles', u'Barbados', u'Molokai', u'Santa Barbara', u'Antigua And Barbuda', u'Alicante', u'Miami', u'Grenada', u'Sint Eustatius', u'Malta', u'Saint Martin', u'Melbourne', u'Hawaii', u'Cook Islands', u'Sint Maarten', u'Rio De Janeiro', u'Trinidad And Tobago', u'Honolulu']\n"
     ]
    }
   ],
   "source": [
    "print(regions)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  30 1231 1139 ...  792 1557  900]\n"
     ]
    }
   ],
   "source": [
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
=======
   "execution_count": 20,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump raw LP text data\n",
    "with open('data/LP_raw.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f, protocol=2)\n",
    "\n",
    "# Dump pickled inverted index\n",
    "with open('data/inv_idx.pickle', 'wb') as f:\n",
    "    pickle.dump(inv_idx, f, protocol=2)\n",
    "\n",
    "# Dump pickled TF-IDF matrix\n",
    "with open('data/tfidf_mat.pickle', 'wb') as f:\n",
    "    pickle.dump(doc_mat, f, protocol=2)\n",
    "    \n",
    "# Dump pickled vocab index matrix\n",
    "with open('data/vocab_idx.pickle', 'wb') as f:\n",
    "    pickle.dump(vocab_idx, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 21,
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Cincinnati Food Tours', 5.0, '1801 Race St, Cincinnati, OH 45202, USA'], ['Gibbon Islands', 5.0, 'Dury Ave, Cincinnati, OH 45220, USA'], ['Children\\xe2\\x80\\x99s Zoo', 5.0, 'Forest Ave, Cincinnati, OH 45220, USA'], ['Statue of James A. Garfield', 5.0, '801-811 Vine St, Cincinnati, OH 45202, USA'], ['Cheetah Encounter', 5.0, 'Dury Ave, Cincinnati, OH 45220, USA'], ['Monkey Island', 4.0, 'Vine St, Cincinnati, OH 45220, USA'], ['World Peace Bell Center', 5.0, '425 York St, Newport, KY 41071, USA'], ['American Legacy Tours', 5.0, '1332 Vine St, Cincinnati, OH 45202, USA'], ['Newport Aquarium', 5.0, '1 Dave Cowens Dr, Newport, KY 41071, USA'], ['Mushroom House', 4.0, '3518 Tarpis Ave, Cincinnati, OH 45208, USA'], ['Fox Preserve', 5.0, '5801 McCray Ct, Cincinnati, OH 45224, USA'], ['The Garage OTR - Home of Segway of Cincinnati', 1.0, '1150 Vine St, Cincinnati, OH 45202, USA'], ['Cincinnati USA Regional Tourism Network', 5.0, '50 E Rivercenter Blvd #1100, Covington, KY 41011, USA'], ['Flottman Company', 4.0, '720 Centre View Blvd, Crestview Hills, KY 41017, USA'], ['Roadtrippers', 5.0, '131 E McMicken Ave, Cincinnati, OH 45202, USA'], ['Newport on the Levee', 4.0, '1 Levee Way, Newport, KY 41071, USA'], ['New Riff Distilling', 5.0, '24 Distillery Way, Newport, KY 41073, USA'], ['Findlay Market', 5.0, '1801 Race St, Cincinnati, OH 45202, USA'], ['Cincinnati Zoo & Botanical Garden', 4.0, '3400 Vine St, Cincinnati, OH 45220, USA'], ['Eden Park', 4.0, '950 Eden Park Dr, Cincinnati, OH 45202, USA'], ['Krohn Conservatory', 5.0, '1501 Eden Park Dr, Cincinnati, OH 45202, USA'], ['Westwood Town Center Historic District', 3.0, 'Cincinnati, OH 45211, USA'], ['Devou Park', 4.0, '1201 Park Dr, Covington, KY 41011, USA'], ['Otto Armleder Dog Park', 5.0, '5057 Wooster Pike, Cincinnati, OH 45226, USA'], ['Washington Park', 5.0, '1230 Elm St, Cincinnati, OH 45202, USA'], ['Cincinnati City Park Water', 5.0, '705 E Pete Rose Way, Cincinnati, OH 45202, USA'], ['Alms Park', 5.0, '710 Tusculum Ave, Cincinnati, OH 45226, USA'], ['Fountain Square South Garage', 5.0, '416 Vine St, Cincinnati, OH 45202, USA'], ['Smale Riverfront Park', 5.0, '100 Ted Berry Way, Cincinnati, OH 45202, USA'], ['Friendship Park', 4.0, '1135 Riverside Dr, Cincinnati, OH 45202, USA'], [\"Yeatman's Cove\", 5.0, '705 E Pete Rose Way, Cincinnati, OH 45202, USA'], ['Rapid Run Park', 2.0, '4450 Rapid Run Rd, Cincinnati, OH 45205, USA'], ['Burnet Woods', 5.0, '3251 Brookline Ave, Cincinnati, OH 45220, USA'], ['The Cincinnatian Hotel', 5.0, '601 Vine St, Cincinnati, OH 45202, USA'], ['Hilton Cincinnati Netherland Plaza', 3.0, '35 W 5th St, Cincinnati, OH 45202, USA'], ['The Westin Cincinnati', 5.0, '21 E 5th St, Cincinnati, OH 45202, USA'], ['Millennium Hotel Cincinnati', 1.0, '150 W 5th St, Cincinnati, OH 45202, USA'], ['Hyatt Regency Cincinnati', 3.0, '151 W 5th St, Cincinnati, OH 45202, USA'], ['Residence Inn by Marriott Cincinnati Downtown/The Phelps', 5.0, '506 E 4th St, Cincinnati, OH 45202, USA'], ['Embassy Suites by Hilton Cincinnati RiverCenter', 1.0, '10 E Rivercenter Blvd, Covington, KY 41011, USA'], ['Cincinnati Marriott at RiverCenter', 5.0, '10 W Rivercenter Blvd, Covington, KY 41011, USA'], ['Courtyard by Marriott Cincinnati Covington', 2.0, '500 W 3rd St, Covington, KY 41011, USA'], ['Radisson Hotel Cincinnati Riverfront', 5.0, '668 W 5th St, Covington, KY 41011, USA'], ['Hampton Inn & Suites Cincinnati/Uptown', 5.0, '3024 Vine St, Cincinnati, OH 45219, USA'], ['Kingsgate Marriott Conference Center at the University of Cincinnati', 3.0, 'Marriott Kingsgate Conference Center, 151 Goodman Dr, Cincinnati, OH 45219, USA'], ['Holiday Inn Express & Suites Cincinnati SE Newport', 5.0, '110 Landmark Dr, Bellevue, KY 41073, USA'], ['Renaissance Cincinnati Downtown Hotel', 5.0, '36 E 4th St, Cincinnati, OH 45202, USA'], ['Xavier University', 5.0, '3800 Victory Pkwy, Cincinnati, OH 45207, USA'], ['Northern Kentucky University', 1.0, 'Nunn Dr, Highland Heights, KY 41099, USA'], ['Cincinnati Christian University', 1.0, '2700 Glenway Ave, Cincinnati, OH 45204, USA']]\n"
     ]
    }
   ],
   "source": [
    "google_place_pickle = open(\"data/google_place.pickle\",\"rb\")\n",
    "google_places = pickle.load(google_place_pickle)\n",
    "print(google_places[\"cincinnati\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopPlacesInRegion(region):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump pickled data\n",
    "# with open('data/LP_raw.pickle', 'wb') as f:\n",
    "#     pickle.dump(data, f)\n",
    "# with open('data/inv_idx.pickle', 'wb') as f:\n",
    "#     pickle.dump(filt_inv_idx, f)\n",
    "# with open('data/tfidf_mat.pickle', 'wb') as f:\n",
    "#     pickle.dump(doc_mat, f)\n",
    "# with open('data/idf.pickle', 'wb') as f:\n",
    "#     pickle.dump(idf, f)\n",
    "# with open('data/vocab_idx.pickle', 'wb') as f:\n",
    "#     pickle.dump(vocab_idx, f)"
   ]
>>>>>>> ce5ce7a130a44af3ab9dc61ab483d9ea1d409a22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
